{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Importing necessary libraries and few classification Algorithms"
      ],
      "metadata": {
        "id": "p6mlHHp48CoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This classification module uses few of the most popoular classification model and is currently covering the concept of supervised learning algorithms only."
      ],
      "metadata": {
        "id": "fWZJsywU8VfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wsloxRmd75eY"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Making class of classifiers <br>\n",
        "Currently I am implementing Random Forest, Decision Tree, K Nearest Neighbour and Multilayer Perceptron Classification Models."
      ],
      "metadata": {
        "id": "467BTPA88zMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModels:\n",
        "    def __init__(self, data, target):\n",
        "        self.X = data\n",
        "        self.y = target\n",
        "    \n",
        "    def split_data(self, test_size=0.2, random_state=42): #keeping test size to 20%\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size,random_state=random_state)\n",
        "    \n",
        "    def scale_data(self): #scaling the train and test dataset, if required.\n",
        "        scaler = StandardScaler()\n",
        "        self.X_train = scaler.fit_transform(self.X_train)\n",
        "        self.X_test = scaler.transform(self.X_test)\n",
        "    \n",
        "    def knn_classifier(self, n_neighbors=5): #K nearest neighbour classifier\n",
        "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        knn.fit(self.X_train, self.y_train)\n",
        "        y_pred = knn.predict(self.X_test)\n",
        "        return accuracy_score(self.y_test, y_pred)\n",
        "    \n",
        "    def decision_tree_classifier(self, max_depth=None): #decision tree classifier\n",
        "        dtree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "        dtree.fit(self.X_train, self.y_train)\n",
        "        y_pred = dtree.predict(self.X_test)\n",
        "        return accuracy_score(self.y_test, y_pred)\n",
        "    \n",
        "    def mlp_classifier(self, hidden_layer_sizes=(100,)): #Multilayer Perceptron Classifier\n",
        "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes)\n",
        "        mlp.fit(self.X_train, self.y_train)\n",
        "        y_pred = mlp.predict(self.X_test)\n",
        "        return accuracy_score(self.y_test, y_pred)\n",
        "    \n",
        "    def random_forest_classifier(self, n_estimators=100): #Random Forest Classifier\n",
        "        rf = RandomForestClassifier(n_estimators=n_estimators)\n",
        "        rf.fit(self.X_train, self.y_train)\n",
        "        y_pred = rf.predict(self.X_test)\n",
        "        return accuracy_score(self.y_test, y_pred)"
      ],
      "metadata": {
        "id": "0mwi0mbi8pnp"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}